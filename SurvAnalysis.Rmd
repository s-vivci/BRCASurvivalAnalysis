---
title: "BRCA Survival Analysis"
author: "Vivek Golla"
output: html_notebook
---

# Background

The following survival analysis project uses the Breast Cancer data generated by the METABRIC GROUP, as downloaded on cbioportal.org. All references are present in the references section.

To begin, we load all of the libraries we're going to use:

```{r}
library(randomForestSRC)
library(ggsurvfit)
library(survival)
library(survminer)
library(data.table)
library(mltools)
library(skimr)
library(knitr)
library(dplyr)
library(tidyverse)
library(readr)
library(ggplot2)
library(tibble)
```

Next, I'm going to read in the data (as a downloaded tsv file)

```{r}
df<-readr::read_tsv("brca_metabric_clinical_data.tsv", show_col_types = FALSE)
```

# Part I: Exploratory Data Analysis (EDA) and Data Cleaning
```{r}
head(df, 10)
glimpse(df)
```

```{r}
skim(df)
```
Based on past studies, I am going to stratify my data based on Age at diagnosis (>50 and <50) and also Tumor Stage.

Some data cleaning. I want proper column names, and also a binary event variable. Dropping NA values and ensuring variables are factor.

```{r}
#make the column names into proper format
names(df) <- make.names(names(df), unique=TRUE)
head(df,3)

```

```{r}
#i want a binary outcomes event variable - only 0 and 1
df$event <- as.numeric(substr(df$Overall.Survival.Status,1,1))

#rename columns and remove NA values
names(df)[names(df) == "Overall.Survival..Months."] <- "time"
names(df)[names(df) == "Age.at.Diagnosis"] <- "age"
df.clean <- df %>% 
  drop_na(time, event, age, Tumor.Stage)
head(df.clean,5)

dim(df.clean)
```
```{r}
#Stratifying - defining the different groups i'' have
df.clean$AgeGroup <- ifelse(df.clean$age > 50, "Above 50", "Below 50")
df.clean$AgeGroup <- as.factor(df.clean$AgeGroup)

df.clean$TumorStage <- as.factor(df.clean$Tumor.Stage)
```

# Part II: Kaplan-Meier Curve

Okay, now that we have our event variable, I'm going to start with a simple Non-Parametric approach - a Kaplan-Meier estimator of the survival function. I will also stratify this based on our previously defined groups.

```{r}
#Based on age group
fit_age <- survfit(Surv(time, event) ~ AgeGroup, data = df.clean, conf.type = "log-log")
fit_age
age.km <- ggsurvplot(fit_age, data = df.clean, 
           pval = TRUE, conf.int =TRUE, legend = "bottom", legend.title = "Age Group", surv.median.line = "hv")
age.km$plot <- age.km$plot + 
theme(legend.text = element_text(size = 8, color = "black", face = "bold"))
age.km
```

```{r}
#Based on Tumor Stage
fit_stage <- survfit(Surv(time, event) ~ Tumor.Stage, data = df.clean, conf.type = "log-log")
fit_stage
tumor.km <- ggsurvplot(fit_stage, data = df.clean, 
           pval = TRUE, conf.int =TRUE, legend = "top", legend.title = "Tumor Stage", surv.median.line = "hv")
tumor.km$plot <- tumor.km$plot + 
theme(legend.text = element_text(size = 8, color = "black", face = "bold"),
      plot.margin = margin(0,0,0,0))
tumor.km

```

# Part III: Log-Rank Test

Next, we're going to compare the survival between distinct groups - those who underwent Chemotherapy and those who didn't. We will accomplish this by using a Log-Rank test (or Mantel-Cox test), which is another nonparametric test. This test essentially compares the hazard rates between the groups to determine if there's a statistically significant difference between them. I start by creating a subset of the original data.
```{r}
lr.subset <- df.clean[c("Patient.ID", "time", "Chemotherapy", "event")]
lr.subset %>%
  drop_na(Chemotherapy)
```

```{r}
fit_lr <- survfit(Surv(time, event) ~ Chemotherapy, data = lr.subset)

surv_plot <- ggsurvplot(fit_lr,
              pval = TRUE,
              pval.method = TRUE
            ) 
# Add labels using ggplot2 syntax
surv_plot$plot + 
  labs(
    x = "Time (months)", 
    y = "Overall Survival Probability"
  ) + 
  theme(plot.margin = margin(0, 0, 0, 0))  # Remove extra margins
```
Interestingly, it appears that the survival curve for patients who underwent Chemotherapy differs from those who did not. p=0.012 < 0.05, which suggests there is a statistically significant difference between survival in both groups.

# Part IV: Estimating x-year survival 

Now, say we want to estimate the probability of surviving a certain amount of months based on our data. For the sake of this analysis, let's do 48 months(4 years). Let's also only use patients who did not undergo chemotherapy (due to the statistically significant difference between survival probability, it may be better to separate the groups).

```{r}
df.nochemo <- df.clean %>%
  filter(Chemotherapy == "NO") %>%
  select(Patient.ID, time, event)

summary(survfit(Surv(time,event) ~ 1 , data=df.nochemo), times=48)
```
We find that the 48-month (4 year) probability of survival in patients who have not undergone Chemotherapy is 87%. 

How about patients that underwent chemotherapy?

```{r}
df.nochemo <- df.clean %>%
  filter(Chemotherapy == "YES") %>%
  select(Patient.ID, time, event)

summary(survfit(Surv(time,event) ~ 1 , data=df.nochemo), times=48)
```
Here we see that the 4-year survival probability of patients in this study who underwent Chemotherapy is 69%.

# Part V: Cox Proportional Hazards Model

Next, we can do regression modeling using a common model in survival analysis - the Cox proportional hazards model. Let's consider the variables HER2 Status and Tumor Size.


The first step is to encode these variables so they can be used to fit the function. For example, what question are we trying to answer? Can we model the impact of certain variables on Survival Time? Is HER2 Status, or Tumor Size related to Survival Times?

The variable HER2 status is categorical so I will use dummy encoding to encode this variables and convert them to a form of binary for my model to use.

Tumor Size is continuous so I won't be encoding it now.

```{r}
#dummy encoding for categorical variables
df.cox <- df.clean
# Ensure categorical variables are factors
df.cox$HER2.Status <- as.factor(df.cox$HER2.Status)

# Convert categorical variables to dummy variables (dropping reference level)
df.cox_dummy <- model.matrix(~ HER2.Status -1 , data = df.cox)  # Drops intercept

# Combine with other variables
df.cox_final <- cbind(df.clean[, c("time", "event", "AgeGroup", "Tumor.Stage", "Tumor.Size")], df.cox_dummy)
df.cox_final <- as.data.frame(df.cox_final)
```


```{r}
cox <- coxph(Surv(time, event) ~ HER2.StatusPositive+Tumor.Size, 
                      data = df.cox_final)
summary(cox)
```
So a Positive HER2 Status and Tumor Size, both have statistically significant impact on Hazards.
In addition, looking at beta (coef) we see that HER2 Positive Status individuals have a higher rate of death (lower survival rate), and the same can be said of Tumor Size as it increases. 
Looking at exp(coef), the hazard ratio, which quantifies relative change in hazard, we see, for example that for a one-unit increase in Tumor Size, the hazard is 1.02 times higher.

But wait, first we should test the proportional hazards assumption for our variables ion the cox-ph model. To use the Cox regression we need to make sure that the hazard ratio of the predictors is constant over time.

```{r}
as_test <- cox.zph(cox)
as_test
```
since the p<0.05 for HER2 Status, we would generally consider that it violates the proportional hazards assumption. Meanwhile, Tumor Size does not violate the assumption. I'll also plot the Schoenfeld residuals so it's easier to see. In this case, the horizontal, unchanging curve of Tumor Size signifies it does not violate the assumption.

```{r}
plot(as_test)
```
We can stratify the Cox-Regression.
```{r}
cox_stratified <- coxph(Surv(time, event) ~ HER2.StatusPositive+Tumor.Size + strata(Tumor.Stage), data=df.cox_final)
summary(cox_stratified)
cox.zph(cox_stratified)
```
# Part VI: Machine Learning Approaches

There are numerous machine learning approaches that can be applied to survival analysis. 
In terms of basic ML models, we have :
Survival Trees,
Bagging Survival Trees,
Random Survival Forest,
Support Vector Regression,
Deep Learning,
Rank based Methods.
In terms of advanced ML models we have :
Active Learning,
Multi-task Learning,
Transfer Learning.

For the sake of this analysis, I will be attempting the Random Survival Forest Approach. I'll create a new subset of my data.

```{r}
data <- df %>%
  select(!c("Patient.ID","Sample.ID","Study.ID","Number.of.Samples.Per.Patient",
            "Sample.Type","Tumor.Stage","Overall.Survival.Status", "Patient.s.Vital.Status", "Relapse.Free.Status..Months.")) %>%
  drop_na(time,event) %>%
  mutate(across(where(is.character), as.factor)) %>%
  drop_na()

new.data <- as.data.frame(data)
```

Create the random survival tree object
```{r}
obj <- rfsrc(Surv(time,event)~., new.data,
             ntree = 1000, nodesize = 5, nsplit = 50, importance = TRUE)
print(obj)
```

Next, I'll create two sample patients, both having median values for all numeric variables (and mode for categorical variables), also one with 25th percentile for Tumor Size, and one with 75th percentile for Tumor Size. Then i'll use the model to make an estimated survival function for both patients and output a visualization of the results. 

```{r}
#Function to get the mode (most frequent category)
get_mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

#Create a newdata dataframe with proper handling of numeric & factor variables
newdata <- data.frame(lapply(obj$xvar, function(col) {
  if (is.numeric(col)) {
    return(median(col, na.rm = TRUE))  # Use median for numeric vars
  } else if (is.factor(col)) {
    return(get_mode(col))  # Use mode for categorical vars
  } else {
    return(NA)  # Catch unexpected types
  }
}))

#Ensure column names match the original data
colnames(newdata) <- obj$xvar.names

#Copy newdata to create two individuals' data
newdata1 <- newdata2 <- newdata

#modify a categorical variable instead of a numeric one
m_var <- "age"
if (m_var %in% obj$xvar.names) {
  newdata1[,which(obj$xvar.names == "Tumor.Size")] <- quantile(obj$xvar$Tumor.Size, 0.25)
  newdata2[,which(obj$xvar.names == "Tumor.Size")] <- quantile(obj$xvar$Tumor.Size, 0.75)
  #levels_available <- levels(obj$xvar[[cat_var]])
  #newdata1[[cat_var]] <- levels_available[1]  # Assign first category
  #newdata2[[cat_var]] <- levels_available[length(levels_available)]  # Assign last category
}

#Bind the modified rows
newdata <- rbind(newdata1, newdata2)

#predict survival curves
y.pred <- predict(obj, newdata = rbind(newdata, obj$xvar)[1:2,])
```

```{r}

par(cex.axis = 2.0, cex.lab = 2.0, cex.main = 2.0, mar = c(6.0,6,1,1), mgp = c(4, 1, 0))
plot(round(y.pred$time.interest,2), y.pred$survival[1,], type="l", xlab="Time (Months)",   
     ylab="Survival", col=1, lty=1, lwd=2)
lines(round(y.pred$time.interest,2), y.pred$survival[2,], col=2, lty=2, lwd=2)

#Move legend outside the plot area and shrink box
legend("topright", 
       legend = c("Tumor Size = 17.05mm", "Tumor Size = 30.00mm"), 
       col = c(1:2), 
       lty = 1:2, 
       lwd = 2, 
       cex = 1.5,  
       bty = "n",  
       xpd = TRUE  
)
```


Next, I am interested in getting the Brier Score for my Random Survival Forest (RSF) analysis. One method uses the Kaplan-Meier censoring distribution estimation, and the second uses RSF censoring distribution estimator. A score closer to 0 indicates better model performance, while a score closer to 1 represents poor performance.

```{r}
##obtain Brier score using KM and RSF censoring distribution estimators
bs.km <- get.brier.survival(obj, cens.mode = "km")$brier.score
bs.rsf <- get.brier.survival(obj, cens.mode = "rfsrc")$brier.score

## plot the brier score
plot(bs.km, type = "s", col = 2)
lines(bs.rsf, type ="s", col = 4)
legend("bottomright", legend = c("cens.model = km", "cens.model = rfsrc"), fill = c(2,4))
```

Next, let's examine the Variable Importance (VIMP). There's a nonparametric measure known as Breiman-Cutler VIMP. It measures prediction error attributable to a variable.

```{r}
invisible(jk.obj <- subsample(obj))
```

```{r}
png("VIMPsur.png", width = 4000, height = 2000, res = 300)
par(mar = c(2,14,1,1))
plot(jk.obj, xlab = "Variable Importance (x 100)", cex = 1.2)
dev.off()

```
![](./VIMPsur.png)

As we can see from the visualization, `Relapse Free Status` is the variable with the highest importance, followed by `Age` and then `Lymph Nodes Examined Positive`. The plot shows delete d jackknife 99% asymptotic normal confidence intervals for the variables from the Breast Cancer RSF analysis. Large positive VIMP indicates high predictive ability.


# REFERENCES
Curtis C, Shah SP, Chin SF, Turashvili G, Rueda OM, Dunning MJ, Speed D, Lynch AG, Samarajiwa S, Yuan Y, Gräf S, Ha G, Haffari G, Bashashati A, Russell R, McKinney S; METABRIC Group; Langerød A, Green A, Provenzano E, Wishart G, Pinder S, Watson P, Markowetz F, Murphy L, Ellis I, Purushotham A, Børresen-Dale AL, Brenton JD, Tavaré S, Caldas C, Aparicio S. The genomic and transcriptomic architecture of 2,000 breast tumours reveals novel subgroups. Nature. 2012 Apr 18;486(7403):346-52. doi: 10.1038/nature10983. PMID: 22522925; PMCID: PMC3440846.

Cerami et al. The cBio Cancer Genomics Portal: An Open Platform for Exploring Multidimensional Cancer Genomics Data. Cancer Discovery. May 2012 2; 401. PubMed.
Gao et al. Integrative analysis of complex cancer genomics and clinical profiles using the cBioPortal. Sci. Signal. 6, pl1 (2013). PubMed.
de Bruijn et al. Analysis and Visualization of Longitudinal Genomic and Clinical Data from the AACR Project GENIE Biopharma Collaborative in cBioPortal. Cancer Res (2023). PubMed.

Abadi A, Yavari P, Dehghani-Arani M, Alavi-Majd H, Ghasemi E, Amanpour F, Bajdik C. Cox models survival analysis based on breast cancer treatments. Iran J Cancer Prev. 2014 Summer;7(3):124-9. PMID: 25250162; PMCID: PMC4171826.


